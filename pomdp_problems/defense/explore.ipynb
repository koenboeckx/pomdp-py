{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pomdp_py\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(p1, p2):\n",
    "    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(pomdp_py.State):\n",
    "    def __init__(self, position, seen, terminal=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            position (tuple): (x,y) position of the agent on the grid.\n",
    "            seen (set): set of squares already seen (0..n**2-1)\n",
    "            terminal (bool, optional): Agent in terminal state. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.position = position\n",
    "        self.seen = seen\n",
    "        self.terminal = terminal\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.position, tuple(self.seen), self.terminal))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, State):\n",
    "            return self.position == self.position and self.terminal == self.terminal #\\ and set(self.seen) == set(other.seen) \\\n",
    "                \n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"State({str(self.position)} | {len(self.seen)} | {str(self.terminal)})\"\n",
    "\n",
    "class Action(pomdp_py.Action):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    def __hash__(self):\n",
    "        return hash(self.name)\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Action):\n",
    "            return self.name == other.name\n",
    "        elif type(other) == str:\n",
    "            return self.name == other\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    def __repr__(self):\n",
    "        return \"Action(%s)\" % self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoveAction(Action):\n",
    "    EAST = (1, 0)  # x is horizontal; x+ is right. y is vertical; y+ is up.\n",
    "    WEST = (-1, 0)\n",
    "    NORTH = (0, -1)\n",
    "    SOUTH = (0, 1)\n",
    "    def __init__(self, motion, name):\n",
    "        if motion not in {MoveAction.EAST, MoveAction.WEST,\n",
    "                          MoveAction.NORTH, MoveAction.SOUTH}:\n",
    "            raise ValueError(\"Invalid move motion %s\" % motion)\n",
    "        self.motion = motion\n",
    "        super().__init__(\"move-%s\" % str(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoveEast = MoveAction(MoveAction.EAST, \"EAST\")\n",
    "MoveWest = MoveAction(MoveAction.WEST, \"WEST\")\n",
    "MoveNorth = MoveAction(MoveAction.NORTH, \"NORTH\")\n",
    "MoveSouth = MoveAction(MoveAction.SOUTH, \"SOUTH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Observation(pomdp_py.Observation):\n",
    "    def __init__(self, view, coords):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            view (tuple): observations in field of view\n",
    "            e=empty, d=obstacle, x=not visible\n",
    "            coords (tuple): coords of elements in view\n",
    "        \"\"\"\n",
    "        self.view = view\n",
    "        self.coords = coords\n",
    "    def __hash__(self):\n",
    "        return hash(self.view)\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Observation):\n",
    "            return self.view == other.view\n",
    "        elif type(other) == str:\n",
    "            return self.view == other\n",
    "    def __str__(self):\n",
    "        return str(self.view) + ' |\\n' + str(self.coords)\n",
    "    def __repr__(self):\n",
    "        return \"Observation(%s)\" % str(self.view)\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_position(position, obstacles, n=10, los=3):\n",
    "        \"\"\"Compute observation from state, taking position\n",
    "        of obstacles into account\n",
    "\n",
    "        Args:\n",
    "            state (State): current agent state\n",
    "            obstacles (list): list of obstacle positions\n",
    "            n (int): gridworld size\n",
    "            los (int): maximum line-of-sight\n",
    "\n",
    "        Returns:\n",
    "            Observation: current observation from state\n",
    "        \"\"\"\n",
    "        if not hasattr(Observation, 'vis_map'):\n",
    "            Observation.make_visibility_map(n, obstacles)\n",
    "        view, coords = [], []\n",
    "        for i in range(n): \n",
    "            for j in range(n):\n",
    "                if euclidean_dist(position, (i, j)) <= los:\n",
    "                    if 0 <= i < n and 0 <= j < n:\n",
    "                        coords.append((i,j))\n",
    "                        if (i, j) in obstacles:\n",
    "                            view.append('d')\n",
    "                        elif not Observation.vis_map[position, (i,j)]: # view at (i, j) is blocked by obstacle(s)\n",
    "                            view.append('x')\n",
    "                        else: # observed empty spot\n",
    "                            view.append('e')\n",
    "        return Observation(tuple(view), tuple(coords))\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_visibility_map(n, obstacles, N=1000):        \n",
    "        def is_visible(p1, p2):\n",
    "            x1, y1 = p1\n",
    "            x2, y2 = p2\n",
    "            xs = np.linspace(x1, x2, N)\n",
    "            ys = np.linspace(y1, y2, N)\n",
    "            for x, y in zip(xs, ys):\n",
    "                if (round(x), round(y)) in obstacles:\n",
    "                    return False \n",
    "            return True \n",
    "\n",
    "        vis_map = {}\n",
    "        for x1 in range(n):\n",
    "            for y1 in range(n):\n",
    "                for x2 in range(n):\n",
    "                    for y2 in range(n):\n",
    "                        vis_map[((x1, y1), (x2, y2))] = is_visible((x1, y1), (x2, y2))\n",
    "        Observation.vis_map = vis_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionModel(pomdp_py.TransitionModel):\n",
    "\n",
    "    \"\"\" The model is deterministic \"\"\"\n",
    "\n",
    "    def __init__(self, n, obstacles, los):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n (int): size of gridworld (n x n)\n",
    "            obstacles (list): list of obstacle positions\n",
    "            los (int): maximum line-of-sight\n",
    "        \"\"\"\n",
    "        self._n = n\n",
    "        self.obstacles = obstacles\n",
    "        self.los = los # required because state is linked to observation (accum of observed squares = state.seen)\n",
    "    \n",
    "    def _move(self, position, action):\n",
    "        \"\"\"Execute move\n",
    "\n",
    "        Args:\n",
    "            position (tuple): current position (x, y) of agent\n",
    "            action (Action): (move) action taken by agent\n",
    "\n",
    "        Returns:\n",
    "            tuple: new position (x', y')\n",
    "        \"\"\"\n",
    "        expected = (position[0] + action.motion[0],\n",
    "                    position[1] + action.motion[1])\n",
    "        if expected in self.obstacles: # bounce against obstacle -> no move\n",
    "            return position\n",
    "        else:\n",
    "            return (max(0, min(position[0] + action.motion[0], self._n-1)),\n",
    "                    max(0, min(position[1] + action.motion[1], self._n-1)))\n",
    "    \n",
    "    def probability(self, next_state, state, action, normalized=False, **kwargs):\n",
    "        if next_state != self.sample(state, action):\n",
    "            return EPSILON\n",
    "        else:\n",
    "            return 1.0 - EPSILON\n",
    "    \n",
    "    def sample(self, state, action):\n",
    "        \"\"\" \n",
    "        terminal = False\n",
    "        if len(set(state.seen)) == self._n**2:\n",
    "            # Question: where update `seen`, since affected by observation\n",
    "            #   maybe: first compute new post\n",
    "            terminal = True\n",
    "        \"\"\"\n",
    "        next_terminal = False\n",
    "        if state.terminal:\n",
    "            next_terminal = True  # already terminated. So no state transition happens\n",
    "            next_position = state.position\n",
    "            next_seen = state.seen\n",
    "        else:\n",
    "            if isinstance(action, MoveAction):\n",
    "                next_position = self._move(state.position, action)\n",
    "                observation = Observation.from_position(next_position, self.obstacles,\n",
    "                                                        self._n, self.los)\n",
    "                next_seen = state.seen | set([c for v, c in zip(observation.view, observation.coords) if v == 'e']) # only retain coords that are viewed\n",
    "                if len(next_seen) == self._n**2 - len(self.obstacles):\n",
    "                    next_terminal = True\n",
    "        return State(next_position, next_seen, next_terminal)\n",
    "    \n",
    "    def argmax(self, state, action):\n",
    "        \"\"\"Returns the most likely next state\"\"\"\n",
    "        return self.sample(state, action) # model is deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservationModel(pomdp_py.ObservationModel):\n",
    "    def __init__(self, n, obstacles, los):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n (int): size of gridworld (n x n)\n",
    "            obstacles (list): list of obstacle positions\n",
    "            los (int): maximum line-of-sight\n",
    "        \"\"\"\n",
    "        self._n = n\n",
    "        self.obstacles = obstacles\n",
    "        self.los = los\n",
    "    \n",
    "    def probability(self, observation, next_state, action):\n",
    "        if observation != self.sample(next_state, action):\n",
    "            return EPSILON\n",
    "        else:\n",
    "            return 1.0 - EPSILON\n",
    "\n",
    "    def sample(self, next_state, action, argmax=False):\n",
    "        return Observation.from_position(next_state.position, self.obstacles,\n",
    "                                        self._n, self.los)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardModel(pomdp_py.RewardModel):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def sample(self, state, action, next_state, normalized=False, **kwargs):\n",
    "        if state.terminal:\n",
    "            return 0  # terminated. No reward\n",
    "        diff = len(next_state.seen) - len(state.seen) # number of new observed squares\n",
    "        return 10*diff - 1 # minus 1 for each step\n",
    "    \n",
    "    def argmax(self, state, action, next_state, normalized=False, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def probability(self, reward, state, action, next_state, normalized=False, **kwargs):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyModel(pomdp_py.RolloutPolicy):\n",
    "    \"\"\"Simple policy model according to problem description.\n",
    "    Used as rollout policy by MCTS\n",
    "    \"\"\"\n",
    "    def __init__(self, n) -> None:\n",
    "        self._all_actions = {MoveEast, MoveWest, MoveNorth, MoveSouth}\n",
    "        self._n = n\n",
    "    \n",
    "    def sample(self, state, normalized=False, **kwargs):\n",
    "        return random.sample(self.get_all_actions(state=state), 1)[0]\n",
    "    \n",
    "    def probability(self, action, state, normalized=False, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def argmax(self, state, normalized=False, **kwargs):\n",
    "        \"\"\"Returns the most likely reward\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_all_actions(self, **kwargs):\n",
    "        \"returns all valid actions\"\n",
    "        state = kwargs.get(\"state\", None)\n",
    "        if state is None:\n",
    "            return self._all_actions\n",
    "        else:\n",
    "            motions = set(self._all_actions)\n",
    "            rover_x, rover_y = state.position\n",
    "            if rover_x == 0:\n",
    "                motions.remove(MoveWest)\n",
    "            if rover_y == 0:\n",
    "                motions.remove(MoveNorth)\n",
    "            if rover_y == self._n - 1:\n",
    "                motions.remove(MoveSouth)\n",
    "            return motions\n",
    "\n",
    "    def rollout(self, state, history=None):\n",
    "        return random.sample(self.get_all_actions(state=state), 1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExploreProblem(pomdp_py.POMDP):\n",
    "    @staticmethod\n",
    "    def random_free_location(n, not_free_locs):\n",
    "        \"\"\"returns a random (x,y) location in nxn grid that is free.\"\"\"\n",
    "        while True:\n",
    "            loc = (random.randint(0, n-1),\n",
    "                   random.randint(0, n-1))\n",
    "            if loc not in not_free_locs:\n",
    "                return loc\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_instance(n, k, type='random', **kwargs):\n",
    "        \"\"\"Returns an init_state and obstacle locations for an instance of Explore(n, k)\n",
    "\n",
    "        Args:\n",
    "            n (int): size of gridworld\n",
    "            k (int): number of obstacles\n",
    "            type (str, optional): How obstacles are placed. Defaults to 'random'.\n",
    "\n",
    "        Returns:\n",
    "            tuple: init_state (type: State), obstacles (type: list)\n",
    "        \"\"\"\n",
    "        # TODO: improve this such that there are never completely blocked squares?\n",
    "        agent_position = [0, 1] #random.randint(0, n-1) #initial position of agent\n",
    "        obstacles = []\n",
    "        if type == 'random':\n",
    "            for _ in range(k):\n",
    "                loc = ExploreProblem.random_free_location(n, obstacles + agent_position)\n",
    "                obstacles.append(loc)\n",
    "        elif type == 'preconfigured':\n",
    "            filename = kwargs.get('filename')\n",
    "            #with open('./defense/terrains/'+filename) as f:\n",
    "            with open('/home/koen/Programming/pomdp-py/pomdp_problems/defense/terrains/'+filename) as f:\n",
    "                for j, line in enumerate(f):\n",
    "                    n = len(line)-1 # takes '/n' into account\n",
    "                    for i, val in enumerate(line[:-1]):\n",
    "                        if val == 'x': # add obstacle\n",
    "                            obstacles.append((i,j))\n",
    "                        if val == 'A':\n",
    "                            agent_position = (i, j)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Initialization type {type} not recognized\")\n",
    "        \n",
    "        init_state = State(tuple(agent_position), set(), False)\n",
    "        return init_state, obstacles\n",
    "    \n",
    "    def print_state(self):\n",
    "        string = \"\\n____MAP____\\n\"\n",
    "        agent_position = self.env.state.position\n",
    "        # true map\n",
    "        for y in range(self._n):\n",
    "            for x in range(self._n):\n",
    "                char = \".\"\n",
    "                if (x,y) in self._obstacles:\n",
    "                    char = 'x'\n",
    "                elif (x,y) == agent_position:\n",
    "                    char = \"A\"\n",
    "                elif (x, y) in self.env.state.seen:\n",
    "                    char = 'o'\n",
    "                string += char\n",
    "            string += \"\\n\"\n",
    "        print(string)\n",
    "        print(f\"state = {self.env.state}\")\n",
    "\n",
    "    def __init__(self, n, k, los, init_state, obstacles, init_belief):\n",
    "        self._n, self._k = n, k\n",
    "        agent = pomdp_py.Agent(init_belief,\n",
    "                               PolicyModel(n),\n",
    "                               TransitionModel(n, obstacles, los),\n",
    "                               ObservationModel(n, obstacles, los),\n",
    "                               RewardModel())\n",
    "        env = pomdp_py.Environment(init_state, \n",
    "                                   TransitionModel(n, obstacles, los),\n",
    "                                   RewardModel())\n",
    "        self._obstacles = obstacles\n",
    "        super().__init__(agent, env, name=\"ExploreProblem\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_particles_belief(n, k, num_particles=200, belief=\"uniform\"):\n",
    "    particles = []\n",
    "    for _ in range(num_particles):\n",
    "        if belief == 'uniform':\n",
    "            state, _ = ExploreProblem.generate_instance(n, k)\n",
    "        else:\n",
    "            raise ValueError(f\"Belief type {belief} not recognized\")\n",
    "        particles.append(state)\n",
    "    init_belief = pomdp_py.Particles(particles)\n",
    "    return init_belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48b06f68fde8e5267d559c126d28fc57c23fe5e458c55ba0accf781034469689"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
